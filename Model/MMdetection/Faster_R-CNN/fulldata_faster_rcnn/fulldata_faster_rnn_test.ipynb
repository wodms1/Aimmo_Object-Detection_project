{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7646ea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aimmo/mmdetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.6\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection\n",
    "\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.coco import CocoDataset,CustomDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b1d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module(force=True)\n",
    "class Aimmo(CustomDataset):\n",
    "    CLASSES = ('car', 'truck', 'bus','pedestrian')\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        data_infos = []\n",
    "    \n",
    "        for image_id in image_list:\n",
    "            filename = os.path.splitext(image_id)[0]#os.path.splitext('{0:}/{1:}'.format(img_prefix, image_id))[0]\n",
    "            #image = cv2.imread(filename)\n",
    "            data_info = {'filename': filename,\n",
    "                         'width': 1920, \n",
    "                         'height': 1024}\n",
    "            label_prefix = self.img_prefix.replace('image', 'middle_texts')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, str(image_id)))\n",
    "\n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [ [float(info) for info in x[1:5]] for x in content]\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_bboxes.append(bbox)\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                else:\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "                    gt_labels_ignore.append(-1)\n",
    "            \n",
    "            data_anno = {\n",
    "              'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels': np.array(gt_labels, dtype=np.compat.long),\n",
    "              'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels_ignore': np.array(gt_labels_ignore, dtype=np.compat.long)\n",
    "            }\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "cfg.dataset_type = 'Aimmo'\n",
    "cfg.data_root = 'data/'\n",
    "\n",
    "cfg.data.train.type = 'Aimmo'\n",
    "cfg.data.train.data_root = 'data/'\n",
    "cfg.data.train.ann_file = 'middle_train.txt'\n",
    "cfg.data.train.img_prefix = 'image'\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'Aimmo'\n",
    "cfg.data.val.data_root = 'data/'\n",
    "cfg.data.val.ann_file = 'middle_val.txt'\n",
    "cfg.data.val.img_prefix = 'image'\n",
    "\n",
    "\n",
    "cfg.data.test.type = 'Aimmo'\n",
    "cfg.data.test.data_root = 'data/'\n",
    "cfg.data.test.ann_file = 'middle_sunday_test.txt'\n",
    "cfg.data.test.img_prefix = 'test/image'\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "\n",
    "\n",
    "cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "cfg.work_dir = 'middle_fulldata'\n",
    "\n",
    "#cfg.lr_config.policy='step'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "cfg.evaluation.metric='mAP'\n",
    "\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 1\n",
    "#cfg.evaluation.save_best='auto'\n",
    "cfg.data.train.pipeline[2].img_scale=[(960,512)]#['Resize']\n",
    "cfg.train_pipeline[2].img_scale=[(960,512)]\n",
    "cfg.test_pipeline[1].img_scale=[(960,512)]\n",
    "cfg.data.val.pipeline[1].img_scale = [(960,512)]\n",
    "cfg.data.test.pipeline[1].img_scale = [(960,512)]\n",
    "cfg.runner.max_epochs = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 12 # Batch size of a single GPU used in testing\n",
    "cfg.data.workers_per_gpu = 0 # Worker to pre-fetch data for each single GPU\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abe18e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: middle_fulldata/epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aimmo/mmdetection/mmdet/datasets/custom.py:181: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "\n",
    "checkpoint_file = 'middle_fulldata/epoch_15.pth'  # 학습한 weight file\n",
    "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32cb543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 393/393, 1.7 task/s, elapsed: 235s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "outputs = single_gpu_test(model_ckpt, data_loader, True, 'my_result', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4b5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------iou_thr: 0.5---------------\n",
      "\n",
      "+------------+------+------+--------+-------+\n",
      "| class      | gts  | dets | recall | ap    |\n",
      "+------------+------+------+--------+-------+\n",
      "| car        | 2057 | 3204 | 0.894  | 0.870 |\n",
      "| truck      | 911  | 1691 | 0.862  | 0.786 |\n",
      "| bus        | 319  | 585  | 0.881  | 0.756 |\n",
      "| pedestrian | 549  | 1233 | 0.698  | 0.581 |\n",
      "+------------+------+------+--------+-------+\n",
      "| mAP        |      |      |        | 0.748 |\n",
      "+------------+------+------+--------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AP50', 0.748), ('mAP', 0.7483304142951965)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.evaluate(outputs,metric='mAP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
