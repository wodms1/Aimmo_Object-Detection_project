{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fdbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aimmo/mmdetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.6\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection\n",
    "\n",
    "# !pip install -q --upgrade wandb\n",
    "# !pip3 install openmim\n",
    "# !mim install mmcv-full\n",
    "# !pip install -e .\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.coco import CocoDataset,CustomDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c76c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module(force=True)\n",
    "class Aimmo(CustomDataset):\n",
    "    CLASSES = ('car', 'truck', 'bus','pedestrian')\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        data_infos = []\n",
    "    \n",
    "        for image_id in image_list:\n",
    "            filename = os.path.splitext(image_id)[0]#os.path.splitext('{0:}/{1:}'.format(img_prefix, image_id))[0]\n",
    "            #image = cv2.imread(filename)\n",
    "            data_info = {'filename': filename,\n",
    "                         'width': 1920, \n",
    "                         'height': 1024}\n",
    "            label_prefix = self.img_prefix.replace('image', 'middle_texts')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, str(image_id)))\n",
    "\n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [ [float(info) for info in x[1:5]] for x in content]\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_bboxes.append(bbox)\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                else:\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "                    gt_labels_ignore.append(-1)\n",
    "            \n",
    "            data_anno = {\n",
    "              'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels': np.array(gt_labels, dtype=np.compat.long),\n",
    "              'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels_ignore': np.array(gt_labels_ignore, dtype=np.compat.long)\n",
    "            }\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52be761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='open-mmlab://detectron2/resnet101_caffe')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=4,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'Aimmo'\n",
      "data_root = 'data/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_train.txt',\n",
      "        img_prefix='image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='data/'),\n",
      "    val=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_val.txt',\n",
      "        img_prefix='image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='data/'),\n",
      "    test=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_sunday_test.txt',\n",
      "        img_prefix='test/image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='data/'))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=15)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/faster_rcnn_r101_caffe_fpn_1x_coco.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "work_dir = 'middle_fulldata'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_file = 'configs/faster_rcnn/faster_rcnn_r101_caffe_fpn_1x_coco.py'\n",
    "checkpoint_file = 'faster_rcnn_r101_caffe_fpn_1x_coco.pth'\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "cfg.dataset_type = 'Aimmo'\n",
    "cfg.data_root = 'data/'\n",
    "\n",
    "cfg.data.train.type = 'Aimmo'\n",
    "cfg.data.train.data_root = 'data/'\n",
    "cfg.data.train.ann_file = 'middle_train.txt'\n",
    "cfg.data.train.img_prefix = 'image'\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'Aimmo'\n",
    "cfg.data.val.data_root = 'data/'\n",
    "cfg.data.val.ann_file = 'middle_val.txt'\n",
    "cfg.data.val.img_prefix = 'image'\n",
    "\n",
    "\n",
    "cfg.data.test.type = 'Aimmo'\n",
    "cfg.data.test.data_root = 'data/'\n",
    "cfg.data.test.ann_file = 'middle_sunday_test.txt'\n",
    "cfg.data.test.img_prefix = 'test/image'\n",
    "\n",
    "cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "\n",
    "cfg.load_from = 'checkpoints/faster_rcnn_r101_caffe_fpn_1x_coco.pth'\n",
    "cfg.work_dir = 'middle_fulldata'\n",
    "\n",
    "cfg.lr_config.policy='step'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "cfg.evaluation.metric='mAP'\n",
    "\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 1\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 1\n",
    "#cfg.evaluation.save_best='auto'\n",
    "#cfg.data.train.pipeline[2].img_scale=[(960,520)]#['Resize']\n",
    "#cfg.train_pipeline[2].img_scale=[(960,520)]\n",
    "#cfg.test_pipeline[1].img_scale=[(960,520)]\n",
    "#cfg.data.val.pipeline[1].img_scale = [(960,520)]\n",
    "#cfg.data.test.pipeline[1].img_scale = [(960,520)]\n",
    "cfg.runner.max_epochs = 15\n",
    "\n",
    "cfg.data.samples_per_gpu = 4 # Batch size of a single GPU used in testing\n",
    "cfg.data.workers_per_gpu = 0 # Worker to pre-fetch data for each single GPU\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60b5f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: middle_fulldata/epoch_13.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aimmo/mmdetection/mmdet/datasets/custom.py:181: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "\n",
    "checkpoint_file = 'middle_fulldata/epoch_11.pth'  # 학습한 weight file\n",
    "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184a6943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 393/393, 1.5 task/s, elapsed: 255s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "outputs = single_gpu_test(model_ckpt, data_loader, True, 'my_result', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a3a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------iou_thr: 0.5---------------\n",
      "\n",
      "+------------+------+------+--------+-------+\n",
      "| class      | gts  | dets | recall | ap    |\n",
      "+------------+------+------+--------+-------+\n",
      "| car        | 2057 | 2968 | 0.906  | 0.888 |\n",
      "| truck      | 911  | 1654 | 0.867  | 0.801 |\n",
      "| bus        | 319  | 645  | 0.893  | 0.819 |\n",
      "| pedestrian | 549  | 1180 | 0.769  | 0.663 |\n",
      "+------------+------+------+--------+-------+\n",
      "| mAP        |      |      |        | 0.793 |\n",
      "+------------+------+------+--------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AP50', 0.793), ('mAP', 0.7929246425628662)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.evaluate(outputs,metric='mAP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
