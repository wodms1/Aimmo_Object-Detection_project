{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a170f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/aimmo/mmdetection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.6\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection\n",
    "\n",
    "# !pip install -q --upgrade wandb\n",
    "# !pip3 install openmim\n",
    "# !mim install mmcv-full\n",
    "# !pip install -e .\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.coco import CocoDataset,CustomDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dbd2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module(force=True)\n",
    "class Aimmo(CustomDataset):\n",
    "    CLASSES = ('car', 'truck', 'bus','pedestrian')\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k:i for i, k in enumerate(self.CLASSES)}\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        data_infos = []\n",
    "    \n",
    "        for image_id in image_list:\n",
    "            filename = os.path.splitext(image_id)[0]#os.path.splitext('{0:}/{1:}'.format(img_prefix, image_id))[0]\n",
    "            #image = cv2.imread(filename)\n",
    "            data_info = {'filename': filename,\n",
    "                         'width': 1920, \n",
    "                         'height': 1024}\n",
    "            label_prefix = self.img_prefix.replace('image', 'middle_texts')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, str(image_id)))\n",
    "\n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [ [float(info) for info in x[1:5]] for x in content]\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_bboxes.append(bbox)\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                else:\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "                    gt_labels_ignore.append(-1)\n",
    "            \n",
    "            data_anno = {\n",
    "              'bboxes': np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels': np.array(gt_labels, dtype=np.compat.long),\n",
    "              'bboxes_ignore': np.array(gt_bboxes_ignore, dtype=np.float32).reshape(-1, 4),\n",
    "              'labels_ignore': np.array(gt_labels_ignore, dtype=np.compat.long)\n",
    "            }\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d53e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type = 'Aimmo'\n",
      "data_root = 'data/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(960, 512), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(960, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=0,\n",
      "    train=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_train.txt',\n",
      "        img_prefix='image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(960, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='data/'),\n",
      "    val=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_val.txt',\n",
      "        img_prefix='image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='data/'),\n",
      "    test=dict(\n",
      "        type='Aimmo',\n",
      "        ann_file='middle_sunday_test.txt',\n",
      "        img_prefix='test/image',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(960, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='data/'))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.01,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0.0001,\n",
      "    paramwise_cfg=dict(bias_lr_mult=2.0, bias_decay_mult=0.0))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.3333333333333333,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=15)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=100, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_dcn_1x_coco-ae4d8b3d.pth'\n",
      "resume_from = 'fcos/epoch_7.pth'\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "model = dict(\n",
      "    type='FCOS',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='open-mmlab://detectron2/resnet50_caffe'),\n",
      "        dcn=dict(type='DCNv2', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, True, True, True)),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        start_level=1,\n",
      "        add_extra_convs='on_output',\n",
      "        num_outs=5,\n",
      "        relu_before_extra_convs=True),\n",
      "    bbox_head=dict(\n",
      "        type='FCOSHead',\n",
      "        num_classes=4,\n",
      "        in_channels=256,\n",
      "        stacked_convs=4,\n",
      "        feat_channels=256,\n",
      "        strides=[8, 16, 32, 64, 128],\n",
      "        loss_cls=dict(\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            gamma=2.0,\n",
      "            alpha=0.25,\n",
      "            loss_weight=1.0),\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=1.0),\n",
      "        loss_centerness=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        norm_on_bbox=True,\n",
      "        centerness_on_reg=True,\n",
      "        dcn_on_last_conv=True,\n",
      "        center_sampling=True,\n",
      "        conv_bias=True),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='MaxIoUAssigner',\n",
      "            pos_iou_thr=0.5,\n",
      "            neg_iou_thr=0.4,\n",
      "            min_pos_iou=0,\n",
      "            ignore_iof_thr=-1),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "work_dir = 'fcos'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_file = 'configs/fcos/fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_dcn_1x_coco.py'\n",
    "checkpoint_file = 'fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_dcn_1x_coco-ae4d8b3d.pth'\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "cfg.load_from = 'checkpoints/fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_dcn_1x_coco-ae4d8b3d.pth'\n",
    "cfg.work_dir = 'fcos'\n",
    "cfg.resume_from = 'fcos/epoch_7.pth'\n",
    "\n",
    "\n",
    "\n",
    "cfg.dataset_type = 'Aimmo'\n",
    "cfg.data_root = 'data/'\n",
    "\n",
    "cfg.train_pipeline[2]['img_scale'] = (960,512)\n",
    "cfg.test_pipeline[1]['img_scale'] = (960,512)\n",
    "\n",
    "\n",
    "\n",
    "cfg.data.train.type = 'Aimmo'\n",
    "cfg.data.train.data_root = 'data/'\n",
    "cfg.data.train.ann_file = 'middle_train.txt'\n",
    "cfg.data.train.img_prefix = 'image'\n",
    "\n",
    "cfg.data.train.pipeline[2]['img_scale'] = (960,512)\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'Aimmo'\n",
    "cfg.data.val.data_root = 'data/'\n",
    "cfg.data.val.ann_file = 'middle_val.txt'\n",
    "cfg.data.val.img_prefix = 'image'\n",
    "\n",
    "cfg.data.val.pipeline[1]['img_scale'] = (960,512)\n",
    "\n",
    "cfg.data.test.type = 'Aimmo'\n",
    "cfg.data.test.data_root = 'data/'\n",
    "cfg.data.test.ann_file = 'middle_sunday_test.txt'\n",
    "cfg.data.test.img_prefix = 'test/image'\n",
    "\n",
    "cfg.data.test.pipeline[1]['img_scale'] = (960,512)\n",
    "\n",
    "cfg.lr_config.policy='step'\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "cfg.evaluation.metric='mAP'\n",
    "\n",
    "\n",
    "cfg.checkpoint_config.interval = 1\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 1\n",
    "cfg.runner['max_epochs'] = 15\n",
    "\n",
    "cfg.model.bbox_head['num_classes'] =4\n",
    "\n",
    "cfg.data.samples_per_gpu = 2\n",
    "cfg.data.workers_per_gpu = 0\n",
    "\n",
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f796b567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: fcos/epoch_15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 22:38:34,384 - root - INFO - ModulatedDeformConvPack backbone.layer2.0.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,386 - root - INFO - ModulatedDeformConvPack backbone.layer2.1.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,388 - root - INFO - ModulatedDeformConvPack backbone.layer2.2.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,390 - root - INFO - ModulatedDeformConvPack backbone.layer2.3.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,392 - root - INFO - ModulatedDeformConvPack backbone.layer3.0.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,395 - root - INFO - ModulatedDeformConvPack backbone.layer3.1.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,398 - root - INFO - ModulatedDeformConvPack backbone.layer3.2.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,401 - root - INFO - ModulatedDeformConvPack backbone.layer3.3.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,403 - root - INFO - ModulatedDeformConvPack backbone.layer3.4.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,405 - root - INFO - ModulatedDeformConvPack backbone.layer3.5.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,407 - root - INFO - ModulatedDeformConvPack backbone.layer4.0.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,413 - root - INFO - ModulatedDeformConvPack backbone.layer4.1.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,417 - root - INFO - ModulatedDeformConvPack backbone.layer4.2.conv2 is upgraded to version 2.\n",
      "2022-12-11 22:38:34,427 - root - INFO - ModulatedDeformConvPack bbox_head.cls_convs.3.conv is upgraded to version 2.\n",
      "2022-12-11 22:38:34,431 - root - INFO - ModulatedDeformConvPack bbox_head.reg_convs.3.conv is upgraded to version 2.\n",
      "/aiffel/aiffel/aimmo/mmdetection/mmdet/datasets/custom.py:181: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import multi_gpu_test, single_gpu_test\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "\n",
    "\n",
    "checkpoint_file = 'fcos/epoch_15.pth'  # 학습한 weight file\n",
    "model_ckpt = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "model_ckpt = MMDataParallel(model_ckpt, device_ids=[0])\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        # 반드시 아래 samples_per_gpu 인자값은 1로 설정\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5da88ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 393/393, 1.8 task/s, elapsed: 214s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "outputs = single_gpu_test(model_ckpt, data_loader, True, 'my_result', 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60b6279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------iou_thr: 0.5---------------\n",
      "\n",
      "+------------+------+-------+--------+-------+\n",
      "| class      | gts  | dets  | recall | ap    |\n",
      "+------------+------+-------+--------+-------+\n",
      "| car        | 2057 | 12056 | 0.925  | 0.873 |\n",
      "| truck      | 911  | 3573  | 0.472  | 0.078 |\n",
      "| bus        | 319  | 8955  | 0.781  | 0.044 |\n",
      "| pedestrian | 549  | 6918  | 0.727  | 0.516 |\n",
      "+------------+------+-------+--------+-------+\n",
      "| mAP        |      |       |        | 0.378 |\n",
      "+------------+------+-------+--------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AP50', 0.378), ('mAP', 0.37784138321876526)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.evaluate(outputs,metric='mAP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f0d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
